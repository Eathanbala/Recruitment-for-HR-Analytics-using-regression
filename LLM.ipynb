{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e49f242b-4e17-4fb4-81d7-709e8a1565e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Data: ['API Key abc123 has Full access, a rate limit of 1000/h, and is used for Production purposes.', 'API Key def456 has Limited access, a rate limit of 500/h, and is used for Development purposes.', 'API Key ghi789 has Full access, a rate limit of Unlimited, and is used for Internal purposes.', 'API Key jkl012 has None access, a rate limit of 0/h, and is used for Inactive purposes.']\n",
      "Vocabulary: {'API': 0, 'Key': 1, 'abc123': 2, 'has': 3, 'Full': 4, 'access,': 5, 'a': 6, 'rate': 7, 'limit': 8, 'of': 9, '1000/h,': 10, 'and': 11, 'is': 12, 'used': 13, 'for': 14, 'Production': 15, 'purposes.': 16, 'def456': 17, 'Limited': 18, '500/h,': 19, 'Development': 20, 'ghi789': 21, 'Unlimited,': 22, 'Internal': 23, 'jkl012': 24, 'None': 25, '0/h,': 26, 'Inactive': 27}\n",
      "Encoded Sentences: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], [0, 1, 17, 3, 18, 5, 6, 7, 8, 9, 19, 11, 12, 13, 14, 20, 16], [0, 1, 21, 3, 4, 5, 6, 7, 8, 9, 22, 11, 12, 13, 14, 23, 16], [0, 1, 24, 3, 25, 5, 6, 7, 8, 9, 26, 11, 12, 13, 14, 27, 16]]\n",
      "Bigram Probabilities: {(0, 1): 0.0625, (1, 2): 0.015625, (2, 3): 0.015625, (3, 4): 0.03125, (4, 5): 0.03125, (5, 6): 0.0625, (6, 7): 0.0625, (7, 8): 0.0625, (8, 9): 0.0625, (9, 10): 0.015625, (10, 11): 0.015625, (11, 12): 0.0625, (12, 13): 0.0625, (13, 14): 0.0625, (14, 15): 0.015625, (15, 16): 0.015625, (1, 17): 0.015625, (17, 3): 0.015625, (3, 18): 0.015625, (18, 5): 0.015625, (9, 19): 0.015625, (19, 11): 0.015625, (14, 20): 0.015625, (20, 16): 0.015625, (1, 21): 0.015625, (21, 3): 0.015625, (9, 22): 0.015625, (22, 11): 0.015625, (14, 23): 0.015625, (23, 16): 0.015625, (1, 24): 0.015625, (24, 3): 0.015625, (3, 25): 0.015625, (25, 5): 0.015625, (9, 26): 0.015625, (26, 11): 0.015625, (14, 27): 0.015625, (27, 16): 0.015625}\n",
      "Generated Text: API Key abc123 has Full access, a rate limit of\n"
     ]
    }
   ],
   "source": [
    "# Recruitment Pipeline Optimization for HR Analytics\n",
    "# Implementing a Simplified Large Language Model (LLM) Simulation for Gemini API Key\n",
    "\n",
    "# Sample Dataset (Text-Based for LLM Simulation)\n",
    "data = [\n",
    "    {\"AIzaSyBBG4nNd_Bll0PvyZ7rgMTNJCZBomS_nI0\": \"abc123\", \"Access\": \"Full\", \"RateLimit\": \"1000/h\", \"Usage\": \"Production\"},\n",
    "    {\"AIzaSyBBG4nNd_Bll0PvyZ7rgMTNJCZBomS_nI0\": \"def456\", \"Access\": \"Limited\", \"RateLimit\": \"500/h\", \"Usage\": \"Development\"},\n",
    "    {\"AIzaSyBBG4nNd_Bll0PvyZ7rgMTNJCZBomS_nI0\": \"ghi789\", \"Access\": \"Full\", \"RateLimit\": \"Unlimited\", \"Usage\": \"Internal\"},\n",
    "    {\"AIzaSyBBG4nNd_Bll0PvyZ7rgMTNJCZBomS_nI0\": \"jkl012\", \"Access\": \"None\", \"RateLimit\": \"0/h\", \"Usage\": \"Inactive\"}\n",
    "]\n",
    "\n",
    "# Step 1: Text Preprocessing\n",
    "# Convert the dataset into a textual format\n",
    "def preprocess_data(data):\n",
    "    text_data = []\n",
    "    for record in data:\n",
    "        text = f\"API Key {record['AIzaSyBBG4nNd_Bll0PvyZ7rgMTNJCZBomS_nI0']} has {record['Access']} access, a rate limit of {record['RateLimit']}, and is used for {record['Usage']} purposes.\"\n",
    "        text_data.append(text)\n",
    "    return text_data\n",
    "\n",
    "text_data = preprocess_data(data)\n",
    "\n",
    "# Step 2: Tokenization\n",
    "# Split text into words manually\n",
    "def tokenize(text):\n",
    "    tokens = []\n",
    "    for sentence in text:\n",
    "        tokens.append(sentence.split())\n",
    "    return tokens\n",
    "\n",
    "tokens = tokenize(text_data)\n",
    "\n",
    "# Step 3: Create a Vocabulary\n",
    "def build_vocabulary(tokens):\n",
    "    vocabulary = {}\n",
    "    index = 0\n",
    "    for sentence in tokens:\n",
    "        for word in sentence:\n",
    "            if word not in vocabulary:\n",
    "                vocabulary[word] = index\n",
    "                index += 1\n",
    "    return vocabulary\n",
    "\n",
    "vocabulary = build_vocabulary(tokens)\n",
    "\n",
    "# Step 4: Encode Sentences into Numerical Format\n",
    "def encode_sentences(tokens, vocabulary):\n",
    "    encoded_sentences = []\n",
    "    for sentence in tokens:\n",
    "        encoded_sentence = [vocabulary[word] for word in sentence]\n",
    "        encoded_sentences.append(encoded_sentence)\n",
    "    return encoded_sentences\n",
    "\n",
    "encoded_sentences = encode_sentences(tokens, vocabulary)\n",
    "\n",
    "# Step 5: Implement a Simplified Language Model\n",
    "# Use a bigram language model (probabilities of word pairs)\n",
    "def build_bigram_model(encoded_sentences):\n",
    "    bigram_counts = {}\n",
    "    for sentence in encoded_sentences:\n",
    "        for i in range(len(sentence) - 1):\n",
    "            bigram = (sentence[i], sentence[i + 1])\n",
    "            if bigram not in bigram_counts:\n",
    "                bigram_counts[bigram] = 0\n",
    "            bigram_counts[bigram] += 1\n",
    "\n",
    "    total_bigrams = sum(bigram_counts.values())\n",
    "    bigram_probabilities = {bigram: count / total_bigrams for bigram, count in bigram_counts.items()}\n",
    "    return bigram_probabilities\n",
    "\n",
    "bigram_model = build_bigram_model(encoded_sentences)\n",
    "\n",
    "# Step 6: Generate Text Using the Model\n",
    "def generate_text(vocabulary, bigram_model, start_word, num_words):\n",
    "    reverse_vocab = {index: word for word, index in vocabulary.items()}\n",
    "    current_word = vocabulary[start_word]\n",
    "    generated_text = [start_word]\n",
    "\n",
    "    for _ in range(num_words - 1):\n",
    "        candidates = [(bigram[1], prob) for bigram, prob in bigram_model.items() if bigram[0] == current_word]\n",
    "        if not candidates:\n",
    "            break\n",
    "\n",
    "        next_word_index = max(candidates, key=lambda x: x[1])[0]\n",
    "        next_word = reverse_vocab[next_word_index]\n",
    "        generated_text.append(next_word)\n",
    "        current_word = next_word_index\n",
    "\n",
    "    return ' '.join(generated_text)\n",
    "\n",
    "# Generate text starting with \"API\"\n",
    "start_word = \"API\"\n",
    "generated_text = generate_text(vocabulary, bigram_model, start_word, 10)\n",
    "\n",
    "# Output Results\n",
    "print(\"Text Data:\", text_data)\n",
    "print(\"Vocabulary:\", vocabulary)\n",
    "print(\"Encoded Sentences:\", encoded_sentences)\n",
    "print(\"Bigram Probabilities:\", bigram_model)\n",
    "print(\"Generated Text:\", generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9acee6-10dd-48b8-b555-75d3b7d68b42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
